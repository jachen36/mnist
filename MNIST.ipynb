{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First neural network using MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1060 6GB (0000:23:00.0)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras expect the images to be in rank2 so we need to add the channel into the image. \n",
    "# because we are using theano as backend, image is channelxheightxwidth\n",
    "x_train = np.expand_dims(x_train,1)\n",
    "x_test = np.expand_dims(x_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final shape of the images after expansion\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the labels are not one hot encoded. \n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encode the labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pixel mean is 33.31842041015625 and the standard deviation is 78.56748962402344\n"
     ]
    }
   ],
   "source": [
    "# normalizing the input helps with training \n",
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)\n",
    "print('The pixel mean is {0} and the standard deviation is {1}'.format(mean_px, std_px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a simple linear model which is similar to logistical regression. \n",
    "# First input is normalized\n",
    "# Second flatten to create a single vector with length of 1x28x28\n",
    "# Third a non-linear activation \n",
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1,28,28), output_shape = (1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation = 'softmax')   \n",
    "        ])\n",
    "    model.compile(Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate image batches \n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(x_train, y_train, batch_size = batch_size)\n",
    "test_batches = gen.flow(x_test, y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.4248 - acc: 0.8758 - val_loss: 0.2891 - val_acc: 0.9164\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s - loss: 0.2993 - acc: 0.9140 - val_loss: 0.2862 - val_acc: 0.9181\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.2851 - acc: 0.9192 - val_loss: 0.2798 - val_acc: 0.9222\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.2772 - acc: 0.9215 - val_loss: 0.2829 - val_acc: 0.9215\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.2729 - acc: 0.9232 - val_loss: 0.2884 - val_acc: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7c3a7b978>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "lm.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch=5, \n",
    "                 validation_data=test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce the learning rate since it looks like it is close to the minimum \n",
    "lm.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 11s - loss: 0.2686 - acc: 0.9256 - val_loss: 0.2784 - val_acc: 0.9196\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 11s - loss: 0.2662 - acc: 0.9258 - val_loss: 0.2804 - val_acc: 0.9223\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 10s - loss: 0.2640 - acc: 0.9265 - val_loss: 0.2815 - val_acc: 0.9209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7c3a7b080>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, batches.n, nb_epoch = 3, \n",
    "                 validation_data = test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much we can do to improve the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Single Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1,28,28), output_shape = (1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation = 'softmax'),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show that you should start with a small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s - loss: 1.2017 - acc: 0.6043 - val_loss: 1.0035 - val_acc: 0.6589\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s - loss: 1.0382 - acc: 0.6476 - val_loss: 1.0823 - val_acc: 0.5986\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s - loss: 0.9952 - acc: 0.6562 - val_loss: 0.9336 - val_acc: 0.6969\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s - loss: 0.9275 - acc: 0.6857 - val_loss: 1.0186 - val_acc: 0.6550\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s - loss: 0.9544 - acc: 0.6770 - val_loss: 0.8499 - val_acc: 0.7095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e03051c50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_test = get_fc_model()\n",
    "fc_test.optimizer.lr = 0.1\n",
    "fc_test.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch = 5, \n",
    "                     validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the training after 5 epoch isn't even close to 1 epoch with lr = 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 11s - loss: 1.5350 - acc: 0.8727 - val_loss: 0.9951 - val_acc: 0.9197\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 11s - loss: 0.7331 - acc: 0.9220 - val_loss: 0.5401 - val_acc: 0.9285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e037b3b70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, samples_per_epoch = batches.n, nb_epoch = 2,\n",
    "                validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 11s - loss: 0.4553 - acc: 0.9292 - val_loss: 0.4031 - val_acc: 0.9259\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 11s - loss: 0.3494 - acc: 0.9350 - val_loss: 0.3307 - val_acc: 0.9341\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 11s - loss: 0.3031 - acc: 0.9369 - val_loss: 0.3043 - val_acc: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e03057320>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch = 3,\n",
    "                validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 10s - loss: 0.2781 - acc: 0.9399 - val_loss: 0.2894 - val_acc: 0.9327\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 11s - loss: 0.2568 - acc: 0.9426 - val_loss: 0.2718 - val_acc: 0.9362\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 10s - loss: 0.2465 - acc: 0.9437 - val_loss: 0.2873 - val_acc: 0.9314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e03057358>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch = 3,\n",
    "                validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks like it is already overfitting use this nn architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic VGG-Style CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vgg_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1,28,28), output_shape = (1,28,28)),\n",
    "        Convolution2D(32,3,3, activation = 'relu'),\n",
    "        Convolution2D(32,3,3, activation = 'relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,3,3, activation = 'relu'),\n",
    "        Convolution2D(64,3,3, activation = 'relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation = 'relu'),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = get_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 12s - loss: 0.1117 - acc: 0.9654 - val_loss: 0.0397 - val_acc: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4df5533b70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch = 1, \n",
    "                 validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.0364 - acc: 0.9890 - val_loss: 0.0233 - val_acc: 0.9917\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 12s - loss: 0.0252 - acc: 0.9923 - val_loss: 0.0223 - val_acc: 0.9930\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.0211 - acc: 0.9934 - val_loss: 0.0265 - val_acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4df553a400>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch = 3,\n",
    "                 validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lower learning rate because it is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 12s - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0248 - val_acc: 0.9944\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.0145 - acc: 0.9955 - val_loss: 0.0304 - val_acc: 0.9910\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0243 - val_acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4df553ab38>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(generator = batches, samples_per_epoch = batches.n, nb_epoch = 3,\n",
    "                 validation_data = test_batches, nb_val_samples = test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range = 8, width_shift_range = 0.08, shear_range = 0.3,\n",
    "                              height_shift_range = 0.08, zoom_range = 0.08)\n",
    "\n",
    "batches_aug = gen.flow(x_train, y_train, batch_size = batch_size)\n",
    "test_batches_aug = gen.flow(x_test, y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = get_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 14s - loss: 0.1993 - acc: 0.9367 - val_loss: 0.0772 - val_acc: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99ae7126a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 1,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 14s - loss: 0.0718 - acc: 0.9780 - val_loss: 0.0479 - val_acc: 0.9847\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.0561 - acc: 0.9827 - val_loss: 0.0426 - val_acc: 0.9864\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.0461 - acc: 0.9854 - val_loss: 0.0366 - val_acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99ae7127f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 3,\n",
    "                  validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0413 - acc: 0.9874 - val_loss: 0.0353 - val_acc: 0.9894\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0395 - val_acc: 0.9871\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 13s - loss: 0.0359 - acc: 0.9884 - val_loss: 0.0286 - val_acc: 0.9916\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 13s - loss: 0.0346 - acc: 0.9893 - val_loss: 0.0343 - val_acc: 0.9889\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0312 - acc: 0.9903 - val_loss: 0.0404 - val_acc: 0.9875\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 13s - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0433 - val_acc: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99ae712828>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr = 0.01\n",
    "vgg.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 6,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0290 - acc: 0.9909 - val_loss: 0.0320 - val_acc: 0.9900\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 13s - loss: 0.0278 - acc: 0.9913 - val_loss: 0.0265 - val_acc: 0.9921\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0304 - val_acc: 0.9901\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0266 - acc: 0.9918 - val_loss: 0.0254 - val_acc: 0.9916\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 13s - loss: 0.0251 - acc: 0.9925 - val_loss: 0.0321 - val_acc: 0.9893\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 14s - loss: 0.0245 - acc: 0.9928 - val_loss: 0.0309 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99ae712b70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr = 0.001\n",
    "vgg.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 6,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vgg_bn():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1,28,28), output_shape = (1,28,28)),\n",
    "        Convolution2D(32,3,3, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Convolution2D(32,3,3, activation = 'relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Convolution2D(64,3,3, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Convolution2D(64,3,3, activation = 'relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Dense(512, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_bn = get_vgg_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s - loss: 0.1667 - acc: 0.9484 - val_loss: 0.0698 - val_acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f999543bd30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 1,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0616 - acc: 0.9812 - val_loss: 0.0528 - val_acc: 0.9836\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0563 - acc: 0.9823 - val_loss: 0.0435 - val_acc: 0.9868\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0494 - acc: 0.9849 - val_loss: 0.0444 - val_acc: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f999541fac8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn.optimizer.lr = 0.1\n",
    "vgg_bn.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 3,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0435 - acc: 0.9864 - val_loss: 0.0491 - val_acc: 0.9841\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0404 - acc: 0.9875 - val_loss: 0.0359 - val_acc: 0.9881\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0409 - acc: 0.9867 - val_loss: 0.0342 - val_acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f999541fcf8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn.optimizer.lr = 0.01\n",
    "vgg_bn.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 3,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 16s - loss: 0.0363 - acc: 0.9889 - val_loss: 0.0431 - val_acc: 0.9868\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 16s - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0287 - val_acc: 0.99080.0\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 16s - loss: 0.0360 - acc: 0.9889 - val_loss: 0.0293 - val_acc: 0.9893\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 16s - loss: 0.0301 - acc: 0.9904 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 16s - loss: 0.0298 - acc: 0.9909 - val_loss: 0.0336 - val_acc: 0.9892\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 16s - loss: 0.0308 - acc: 0.9906 - val_loss: 0.0323 - val_acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f999541feb8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn.optimizer.lr = 0.001\n",
    "vgg_bn.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 6,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Batchnorm + dropout + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vgg_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1,28,28), output_shape = (1,28,28)),\n",
    "        Convolution2D(32,3,3, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Convolution2D(32,3,3, activation = 'relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Convolution2D(64,3,3, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Convolution2D(64,3,3, activation = 'relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Dense(512, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_bn_do = get_vgg_bn_do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s - loss: 0.2255 - acc: 0.9313 - val_loss: 0.0767 - val_acc: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9991487c88>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn_do.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 1,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0908 - acc: 0.9718 - val_loss: 0.0612 - val_acc: 0.9809\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 15s - loss: 0.0721 - acc: 0.9780 - val_loss: 0.0423 - val_acc: 0.9865\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 16s - loss: 0.0680 - acc: 0.9793 - val_loss: 0.0351 - val_acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9991487e10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn_do.optimizer.lr = 0.1\n",
    "vgg_bn_do.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 3,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0603 - acc: 0.9811 - val_loss: 0.0417 - val_acc: 0.9862\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0565 - acc: 0.9826 - val_loss: 0.0396 - val_acc: 0.9886\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0542 - acc: 0.9834 - val_loss: 0.0352 - val_acc: 0.9889\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0495 - acc: 0.9845 - val_loss: 0.0384 - val_acc: 0.9871\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0471 - acc: 0.9859 - val_loss: 0.0337 - val_acc: 0.9904\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0452 - acc: 0.9856 - val_loss: 0.0304 - val_acc: 0.9906\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0446 - acc: 0.9857 - val_loss: 0.0290 - val_acc: 0.9906\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0436 - acc: 0.9873 - val_loss: 0.0278 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9991487eb8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_bn_do.optimizer.lr = 0.001\n",
    "vgg_bn_do.fit_generator(generator = batches_aug, samples_per_epoch = batches_aug.n, nb_epoch = 8,\n",
    "                 validation_data = test_batches_aug, nb_val_samples = test_batches_aug.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(train_batch):\n",
    "    model = get_vgg_bn_do()\n",
    "    model.fit_generator(generator = train_batch, samples_per_epoch = train_batch.n, nb_epoch = 1,\n",
    "                       verbose = 0)\n",
    "    \n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(generator = train_batch, samples_per_epoch = train_batch.n, nb_epoch = 4,\n",
    "                       verbose = 0)\n",
    "    \n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(generator = train_batch, samples_per_epoch = train_batch.n, nb_epoch = 4,\n",
    "                       verbose = 0)\n",
    "    \n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(generator = train_batch, samples_per_epoch = train_batch.n, nb_epoch = 6,\n",
    "                       verbose = 0)\n",
    "    \n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(generator = train_batch, samples_per_epoch = train_batch.n, nb_epoch = 12,\n",
    "                       verbose = 0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fit_model(batches_aug) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "model_path = path + 'model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn_mnist-'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(x_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0133,  0.996 ],\n",
       "       [ 0.0142,  0.9964],\n",
       "       [ 0.0171,  0.9942],\n",
       "       [ 0.0133,  0.9956],\n",
       "       [ 0.0145,  0.9954],\n",
       "       [ 0.0156,  0.9954]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0147,  0.9955])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(x_test, batch_size = 256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10000, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.9969000220298767, dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
